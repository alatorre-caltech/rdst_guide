\documentclass[12pt]{report}
\title{R(D*) Analysis Guide}
\author{Anthony LaTorre}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{listings}
\lstset{
  basicstyle=\ttfamily,
  columns=fullflexible,
  frame=none,
  breaklines=true,
  postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
}
\usepackage{xcolor}
\usepackage[framemethod=TikZ]{mdframed}
\mdfsetup{nobreak=true}
\usepackage{fullpage}
\definecolor{light-gray}{gray}{0.95} %the shade of grey that stack exchange uses
\begin{document}
\maketitle
\tableofcontents
\begin{abstract}
This is a short document intended to provide an intro to the R(D*) analysis and talk about some of the current problems.
\end{abstract}
\chapter{Introduction}
This document is intended to give a brief overview of the technical details of
the software and some current problems with the R(D*) analysis. Before diving
in, you should read the following documents to help you get a better idea of
the overall analysis strategy:
\begin{itemize}
\item Analysis Note: \url{https://cms.cern.ch/iCMS/jsp/db_notes/noteInfo.jsp?cmsnoteid=CMS%20AN-2019/162}
\item Olmo's Thesis: \url{https://thesis.library.caltech.edu/15019/1/olmo_cerri_2023_thesis.pdf}
\end{itemize}
\chapter{Software}
The R(D*) analysis software consists of three repositories:
\begin{enumerate}
\item \href{https://github.com/alatorre-caltech/BPH\_RD\_Analysis}{BPH\_RD\_Analysis}
\item \href{https://github.com/alatorre-caltech/BPH\_RDntuplizer}{BPH\_RDntuplizer}
\item \href{https://github.com/alatorre-caltech/BPH\_CMSMCGen}{BPH\_CMSMCGen}
\end{enumerate}
\section{Getting Started}
Before running any of the software it is necessary to set up your environment.
These instructions will assume you are running things on the Caltech Tier2
login nodes, but the instructions should be similar for any computer.

First, we are going to set up a container that will run RHEL7 since that is
what the software was developed on\footnote{I'm not actually sure if there is
any good reason to have everything running under RHEL7. It makes a lot of
things much more painful, and so if everything can compile and give identical
results under Alma Linux 8 that would be much much better.}.

\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=15,innerbottommargin=15, outerlinewidth=1, linecolor=light-gray,roundcorner=20pt]
\begin{lstlisting}
$ mkdir ~/bin
$ echo "export PATH=$HOME/bin:$PATH" >> ~/.bash_profile
$ echo "source /cvmfs/cms.cern.ch/cmsset_default.sh" >> ~/.bash_profile
$ source ~/.bash_profile
$ cp `which cmssw-cc7` ~/bin
\end{lstlisting}
\end{mdframed}

Then, edit the file \texttt{~/bin/cmssw-cc7} and add the following line:

\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=15,innerbottommargin=15, outerlinewidth=1, linecolor=light-gray,roundcorner=20pt]
\begin{lstlisting}
SINGULARITY_BINDPATH=$SINGULARITY_BINDPATH,/storage/:/storage/
\end{lstlisting}
\end{mdframed}

just before the last line, i.e.

\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=15,innerbottommargin=15, outerlinewidth=1, linecolor=light-gray,roundcorner=20pt]
\begin{lstlisting}
[...]
SINGULARITY_BINDPATH=$SINGULARITY_BINDPATH,/storage/:/storage/
singularity -s exec ${SINGULARITY_OPTS} $UNPACKED_IMAGE sh -c "${CMD_TO_RUN[@]}"
\end{lstlisting}
\end{mdframed}

Now we can create the main directory that everything will be put under, and
create the CMSSW environments needed:
\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=15,innerbottommargin=15, outerlinewidth=1, linecolor=light-gray,roundcorner=20pt]
\begin{lstlisting}
$ cd
$ cmssw-cc7
Singularity> source /cvmfs/cms.cern.ch/cmsset_default.sh
Singularity> mkdir RDstAnalysis
Singularity> cd RDstAnalysis
Singularity> export SCRAM_ARCH=slc7_amd64_gcc700
Singularity> cmsrel CMSSW_10_2_3  # For the ntuplizer
Singularity> cmsrel CMSSW_10_2_13 # For combine
Singularity> # Now, we get out of the container and set up a final environment for when we
Singularity> # don't need to run anything platform specific
Singularity> exit
$ cd ~/RDstAnalysis
$ source /cvmfs/cms.cern.ch/cmsset_default.sh
$ export SCRAM_ARCH=cc8_amd64_gcc9
$ cmsrel CMSSW_11_2_0
\end{lstlisting}
\end{mdframed}
It is important to use the exact same directory structure since this is assumed
in much of the code.

Next, we are going to add some basic stuff to our .bashrc so that we have
access to the CMS programs, etc. every time we log in. To do so add the
following to your .bashrc when you log in:

\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=15,innerbottommargin=15, outerlinewidth=1, linecolor=light-gray,roundcorner=20pt]
\begin{lstlisting}
ulimit -s unlimited

PATH=$HOME/bin:$PATH:$HOME/.local/bin

export PATH
export EDITOR=vim

export HISTFILESIZE=
export HISTSIZE=

if [[ $- == *i* ]]; then
    source /cvmfs/cms.cern.ch/cmsset_default.sh
    export X509_USER_CERT=$HOME/.globus/usercert.pem
    export X509_USER_KEY=$HOME/.globus/private/userkey.pem
    export X509_USER_PROXY=/tmp/x509up_u${EUID}
    export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.14.2/Linux-x86_64/bin:${PATH}
    export BOOST_ROOT=/cvmfs/sft.cern.ch/lcg/releases/Boost/1.66.0-f50b5/x86_64-centos7-gcc7-opt/
    export HEPMC_DIR=/cvmfs/sft.cern.ch/lcg/external/HepMC/2.06.08/x86_64-slc6-gcc48-opt
    cd $HOME/RDstAnalysis/CMSSW_11_2_0/
    eval `scramv1 runtime -sh`
    source $HOME/RDstAnalysis/BPH_RD_Analysis/env.sh
    cd -
fi

\end{lstlisting}
\end{mdframed}

\subsection{Installing the ntuplizer}
Next, we will install the ntuplizer:
\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=15,innerbottommargin=15, outerlinewidth=1, linecolor=light-gray,roundcorner=20pt]
\begin{lstlisting}
$ cmssw-cc7
Singularity> cd ~/RDstAnalysis/CMSSW_10_2_3/src
Singularity> cmsenv
Singularity> mkdir ntuplizer
Singularity> cd ntuplizer
Singularity> wget https://hammer.physics.lbl.gov/Hammer-1.2.1-Source.tar.gz
Singularity> tar -xzf Hammer-1.2.1-Source.tar.gz
Singularity> mkdir Hammer-build
Singularity> cd Hammer-build
Singularity> export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.14.2/Linux-x86_64/bin:${PATH}
Singularity> export BOOST_ROOT=/cvmfs/sft.cern.ch/lcg/releases/Boost/1.66.0-f50b5/x86_64-centos7-gcc7-opt/
Singularity> export HEPMC_DIR=/cvmfs/sft.cern.ch/lcg/external/HepMC/2.06.08/x86_64-slc6-gcc48-opt
Singularity> cmake -DCMAKE_INSTALL_PREFIX=../Hammer-install -DENABLE_TESTS=ON -DWITH_ROOT=OFF -DWITH_EXAMPLES=OFF -DINSTALL_EXTERNAL_DEPENDENCIES=ON -DWITH_PYTHON=OFF -DBUILD_SHARED_LIBS=ON -DFORCE_YAMLCPP_INSTALL=ON -DCMAKE_CXX_FLAGS="-pthread" -DBOOST_ROOT=/cvmfs/sft.cern.ch/lcg/releases/Boost/1.64.0-0809c/x86_64-centos7-gcc7-opt/ ../Hammer-1.2.1-Source
\end{lstlisting}
\end{mdframed}
Next, change line 79 (FIXME: is it still line 79? has this been fixed upstream yet?) of \texttt{Hammer-1.2.1-Source/src/Amplitudes/AmplBDstarDPiLepNu.cc} from \texttt{const FourMomentum\& pPion = daughters[4].momentum();} to \texttt{const FourMomentum\& pPion = pDstarmes - pDmes;}. Then continue to compilation:
\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=15,innerbottommargin=15, outerlinewidth=1, linecolor=light-gray,roundcorner=20pt]
\begin{lstlisting}
Singularity> make -j24; make install -j24
Singularity> cd $CMSSW_BASE/lib/slc7_amd64_gcc700
Singularity> cp ../../src/ntuplizer/Hammer-install/lib64/*.so.* ./
Singularity> cp ../../src/ntuplizer/Hammer-install/lib64/Hammer/*.so.* ./
Singularity> cd $CMSSW_BASE/src/ntuplizer/Hammer-build
Singularity> ctest -V
Singularity> cd ..
Singularity> rm -rf Hammer-1.2.1-Source.tar.gz Hammer-build
\end{lstlisting}
\end{mdframed}
Now, we can get the ntuplizer code and compile it:
\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=15,innerbottommargin=15, outerlinewidth=1, linecolor=light-gray,roundcorner=20pt]
\begin{lstlisting}
Singularity> cd ~/RDstAnalysis/CMSSW_10_2_3/src/ntuplizer
Singularity> git clone https://github.com/alatorre-caltech/BPH_RDntuplizer.git
Singularity> cd BPH_RDntuplizer
Singularity> scram b -j12
\end{lstlisting}
\end{mdframed}

You can find more instructions on running the ntuplizer in the README at \url{https://github.com/alatorre-caltech/BPH_RDntuplizer}.

\section{BPH\_RD\_Analysis}
The BPH\_RD\_Analysis contains the following scripts:
\begin{itemize}
\item B2DstMu\_skimCAND\_v1.py which converts the ntuples for the normal B -> D* mu nu analysis into ``skimmed'' data files which are used as input to the final fit
\item B2JpsiKst\_skimCAND\_v1.py which converts the ntuples for the calibration samples into ``skimmed'' data files
\item generatorEfficiency.py which looks at the MiniAOD logs to produce text files which contain the efficiency of tagging a given sample. These efficiencies are used in the final fit when computing the overall normalization for each sample.
\item triggerEfficiencies.py and triggerEfficienciesScaleFactors.py are used to compute the trigger efficiency corrections.
\item kinematicCalibration\_Bd\_JpsiKst.py is used to compute the corrections for the B pT and extra track pT, etc. from the calibration sample
\item forcedDecayChannelsFactors\_v2.ipynb is used to calculate the normalization of the branching ratios for each sample based on what decays were forced in the MC card
\end{itemize}
\subsection{Running the Skimmer}
To produce ``skimmed'' data files from the ntuples, you can run:
\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=15,innerbottommargin=15, outerlinewidth=1, linecolor=light-gray,roundcorner=20pt]
\begin{lstlisting}
$ python B2DstMu_skimCAND_v1.py -d '.*' --cat low
$ python B2DstMu_skimCAND_v1.py -d '.*' --cat mid
$ python B2DstMu_skimCAND_v1.py -d '.*' --cat high
\end{lstlisting}
\end{mdframed}
Note that it's possible to run these three in parallel. To run the same for the calibration data:
\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=15,innerbottommargin=15, outerlinewidth=1, linecolor=light-gray,roundcorner=20pt]
\begin{lstlisting}
$ python B2JpsiKst_skimCAND_v1.py -d '.*' --cat low
$ python B2JpsiKst_skimCAND_v1.py -d '.*' --cat mid
$ python B2JpsiKst_skimCAND_v1.py -d '.*' --cat high
\end{lstlisting}
\end{mdframed}
\subsection{Computing the Trigger Efficiency}
To compute the trigger efficiencies for data and MC you can run:
\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=15,innerbottommargin=15, outerlinewidth=1, linecolor=light-gray,roundcorner=20pt]
\begin{lstlisting}
$ for t in "Mu7_IP4" "Mu9_IP6" "Mu12_IP6"; do ./triggerEfficiencies.py -v [version] -t $t -d RD --refIP BS; done
$ for t in "Mu7_IP4" "Mu9_IP6" "Mu12_IP6"; do ./triggerEfficiencies.py -v [version] -t $t -d MC --refIP BS; done
$ for t in "Mu7_IP4" "Mu9_IP6" "Mu12_IP6"; do ./triggerEfficienciesScaleFactors.py -v [version] -t $t --refIP BS; done
\end{lstlisting}
\end{mdframed}
\subsection{Editing IPython Notebooks}
To edit ipython notebooks from a remote server like login-2, it is necessary to do some port forwarding. Here is how I do it (for example: to modify forcedDecayChannelsFactors\_v2.ipynb).
\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=15,innerbottommargin=15, outerlinewidth=1, linecolor=light-gray,roundcorner=20pt]
\begin{lstlisting}
$ ssh login-2.hep.caltech.edu
$ cd RDstAnalysis/BPH_RD_Analysis/scripts
$ jupyter-notebook --no-browser --port 1234
\end{lstlisting}
\end{mdframed}
Then, on your local machine:
\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=15,innerbottommargin=15, outerlinewidth=1, linecolor=light-gray,roundcorner=20pt]
\begin{lstlisting}
$ ssh ssh -NL 1234:localhost:1234 login-2.hep.caltech.edu
\end{lstlisting}
\end{mdframed}
Then you should be able to visit the link that the jupyter notebook gives you
on your local machine.
\section{BPH\_RDntuplizer}
\chapter{Current Problems}
\section{Covariance Matrices}
We discovered that the covariance matrices for all the tracks making up both
the secondary tracks from the B decay and the primary vertex tracks do not
agree between data and MC. In particular, the matrix element representing the
impact parameter error was \emph{very} different between data and MC, but many
of the other matrix elements also had different distributions.

We gave a short talk to the tracking POG about the impact parameter matrix
element specifically and were told it was a known bug that the data error was
overestimated. Therefore, to correct for that specific bug we simply add an
overall offset to the impact parameter error for MC. You can see that here:
\url{https://github.com/alatorre-caltech/BPH_RDntuplizer/blob/0d97cbf02a59de63b8b56fbe52935ad7264286f5/plugins/VtxUtils.cc#L221}.

We are also currently correcting two more matrix elements by simply applying an
offset to the MC matrix elements. However, it needs to be stressed that we do
not understand the origin of these differences and some of the differences
between data and MC for these have a complex structure (eta dependence). See
Figure~\ref{fig:mu-eta-vs-cov-4-4} for an example.

\begin{figure}
\centering
\includegraphics[width=\linewidth]{mu_eta_vs_cov_4_4.png}
\caption{2D histogram showing the 4th covariance matrix element of the muon as a function of $\eta$ for MC (top) and data (bottom). As you can see there is a distinctive feature in the barrel region for the MC which is not at all present in the data.}
\label{fig:mu-eta-vs-cov-4-4}
\end{figure}

These covariance matrix elements are extremely important for both the secondary
track fits and for the primary vertex fit. They are important for the secondary
track fits because the entire analysis relies on fitting these tracks within
the CMSSW framework which uses the covariance matrix when fitting multiple
tracks. Similarly, the primary vertex resolution is important as it is used to
compute the B direction when computing all of the final observables (missing
mass, etc.).

Fundamentally, I believe the current approach of trying to fix these issues
after the fact by applying corrections at the analysis level is wrong. Whatever
is causing these issues in the other matrix elements represents some
fundamental mismodelling of the detector in the Monte Carlo and because of the
complex nature of how these variables enter the analysis (through complex fits
of tracks) and so should be fixed at the simulation level and not papered over
after the fact.

\section{Primary Vertex Resolution}
As mentioned in the previous section, there are noticeable differences in the
covariance matrix between data and MC. In addition, there are obvious
differences in the primary vertex fit. If you look at the chi-squared and
number of degrees of freedom for this fit you find that these distributions do
not at all agree between data and MC, and this is important since the primary
vertex is used to compute all the final observables.

The current hypothesis is that these problems are caused by a mismodelling of
the radiation damage in the first pixel layer of the tracker. We have currently
tried to take this into account by adding a Gaussian smearing on the x, y, and
z coordinate of the primary vertex fit in MC. You can see that here:
\url{https://github.com/alatorre-caltech/BPH_RD_Analysis/blob/e9d8ac7ec8585be1badd68e43c1c48aa11751005/scripts/B2DstMu_skimCAND_v1.py#L268}.
Currently we actually apply a beamspot constraint at the ntuplization
level\footnote{Not clear if this is a good idea due to the fact that the
beamspot wandering is not actually simulated in MC.}, so that later we
primarily only have to apply a significant smearing in the z direction.

The vertex resolution is extremely important, and in my opinion it is not the
correct approach to try to fix a mismodelling of the radiation damage in the
tracker by applying ad-hoc gaussian smearing after the fact. It clearly seems
to help the fit a lot, but it's unlikely that the complex effects of this
mismodelling cannot be captured with a simple gaussian smearing.

\section{Mismodelling in the Plus Minus Control Region}
It seems likely that there is at least one background in the control region
with two tracks that are oppositely charged that we are not currently modeling.
This is evident from two plots: the visible mass and the mass of the two extra
tracks.

\end{document}
